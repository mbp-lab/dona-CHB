{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c038cfe9-1a8d-4364-8c9b-35ff9963c30f",
   "metadata": {},
   "source": [
    "### This notebook is used to derive metrics for quantifying the participants' activity times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d4c9dc-5f6e-4c46-9b9c-ccd3ba6d82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(1, os.path.abspath('../../..'))\n",
    "sys.path.insert(1, os.path.abspath('../'))\n",
    "\n",
    "raw_data_path = \"../../data/raw\"\n",
    "processed_data_path = \"../../data/processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da48f0-6cab-4515-a845-1b3893c68ffa",
   "metadata": {},
   "source": [
    "### Load messaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8ac633-1b95-4618-8a8f-4eaa0f211817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the donation info from the data dable\n",
    "donation_table = pd.read_csv(Path(f'{raw_data_path}/donation_table_CHB_filtered.csv'))\n",
    "\n",
    "# Load donated messages from the relevant donations (e.g. those who filled in both surveys)\n",
    "messages_table = pd.read_csv(Path(f'{raw_data_path}/messages_table_CHB_filtered.csv'))\n",
    "messages_table['datetime'] = pd.to_datetime(messages_table['datetime']) # ensure the date is in datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447e560-6d07-461a-820d-594a9cef2a37",
   "metadata": {},
   "source": [
    "### Calculate the response probabilities of the participants (egos) and their contacts (alters) within the specified bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0e19fa-207b-4111-98eb-5579241dd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import bin_probability\n",
    "from modules.metrics import normalized_entropy\n",
    "\n",
    "bins = [[0,6],[6,12],[12,18],[18,24]] # [lower, upper) for bin calculation!\n",
    "bin_columns = ['activity-00:00-05:59','activity-06:00-11:59','activity-12:00-17:59','activity-18:00-23:59']\n",
    "bin_labels = ['00:00 - 05:59','06:00 - 11:59','12:00 - 17:59','18:00 - 23:59']\n",
    "\n",
    "info_dict = {}\n",
    "\n",
    "for donation_id, donor_id, external_id in zip(donation_table['donation_id'], donation_table['donor_id'], donation_table['external_id']):\n",
    "    ego_messages = messages_table[messages_table['sender_id'] == donor_id].copy()\n",
    "\n",
    "    # Extract hour and date\n",
    "    ego_messages['hour'] = ego_messages['datetime'].dt.hour\n",
    "    ego_messages['date'] = ego_messages['datetime'].dt.date\n",
    "\n",
    "    # Calculate bin proportions and entropy\n",
    "    bin_proportions = bin_probability(ego_messages['hour'].values, bins, bin_columns)\n",
    "    entropy = normalized_entropy(list(bin_proportions.values()))\n",
    "\n",
    "    # Calculate daily active hour stats\n",
    "    daily_hours = ego_messages.groupby('date')['hour'].nunique()\n",
    "    daily_stats = {'mean_daily_hours': daily_hours.mean(),\n",
    "        'median_daily_hours': daily_hours.median(),\n",
    "        'std_daily_hours': daily_hours.std(),\n",
    "        'max_daily_hours': daily_hours.max()}\n",
    "\n",
    "    # Combine all info\n",
    "    info = {'normalized_entropy': entropy,\n",
    "        **daily_stats,\n",
    "        **bin_proportions}\n",
    "    info_dict[external_id] = info\n",
    "\n",
    "# Final DataFrame\n",
    "times_table = pd.DataFrame.from_dict(info_dict, orient='index').reset_index().rename(columns={'index': 'external_id'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2139d-c05b-4891-ad67-ff1c4da0fef8",
   "metadata": {},
   "source": [
    "### Absolute activity time saving\n",
    "\n",
    "Combine the activity metrics with the donor self-reports and save it all in a table for later analysis the activity time information with the donor self-reports and save it all in a table for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6e202e-0ab2-4225-be8b-197b344c579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_survey = pd.read_excel(Path(f'{raw_data_path}/pre-survey_CHB.xlsx'))[['external_id']+bin_columns]\n",
    "post_survey = pd.read_excel(Path(f'{raw_data_path}/post-survey_CHB.xlsx'))[['external_id']+bin_columns]\n",
    "\n",
    "# Map the strings to numerical values\n",
    "bin_response_mapping = {'Yes': 1, 'No': 0}\n",
    "for col in bin_columns:\n",
    "    pre_survey[f'{col}'] = pre_survey[f'{col}'].map(bin_response_mapping)\n",
    "    post_survey[f'{col}'] = post_survey[f'{col}'].map(bin_response_mapping)\n",
    "    \n",
    "absolute_survey = pd.merge(pre_survey, post_survey, on='external_id', how='inner', suffixes=('_pre', '_post'))\n",
    "absolute_survey = absolute_survey.dropna(subset=[f\"{col}_pre\" for col in bin_columns] + [f\"{col}_post\" for col in bin_columns])\n",
    "absolute_times_data = pd.merge(absolute_survey,times_table[['external_id']+bin_columns],on='external_id', how ='inner')\n",
    "absolute_times_data.to_excel(Path(f'{processed_data_path}/absolute_times_data.xlsx'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f7903-6bad-4a47-890d-6bce37c8c2eb",
   "metadata": {},
   "source": [
    "### Relative activity time saving\n",
    "\n",
    "Combine the relative activity metrics with the donor self-reports and save it all in a table for later analysis the activity time information with the donor self-reports and save it all in a table for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b21973-56ac-409f-96a2-a181feb7d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import map_7point_likert\n",
    "question_column = 'texting_all_day'\n",
    "\n",
    "# Load and transform the question columns relevant for this aspect\n",
    "pre_survey = map_7point_likert(Path(f'{raw_data_path}/pre-survey_CHB.xlsx'), question_column)\n",
    "post_survey = map_7point_likert(Path(f'{raw_data_path}/post-survey_CHB.xlsx'), question_column)\n",
    "relative_survey= pd.merge(pre_survey, post_survey, on='external_id', how='inner', suffixes=('_pre', '_post'))\n",
    "relative_survey[f'{question_column}_diff'] = relative_survey[f'{question_column}_post'] - relative_survey[f'{question_column}_pre']\n",
    "\n",
    "# Pair objective data with the subjective assessments based on exterenal_id\n",
    "time_obj = times_table[['external_id','normalized_entropy','mean_daily_hours','median_daily_hours','std_daily_hours','max_daily_hours']]\n",
    "all_data = pd.merge(relative_survey,time_obj,on='external_id', how ='inner')\n",
    "all_data.to_excel(Path(f'{processed_data_path}/relative_times_data.xlsx'),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa89288-9d32-4251-8d2f-667f167d46c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
