{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68d58e2-1d5e-41b0-a424-14aee1b96edb",
   "metadata": {},
   "source": [
    "### This notebook is used to derive metrics for chat equality index and combine them with the subjective scores. \n",
    "\n",
    "Chat equality is derived by the words sent by the data donor (participant) in each of their chats. There are different metrics but 1-Gini index (rGini) is the default. The subjective scores of this concept are assessed by asking the participant the following question \"I send approximately the same number of words per month to all of my contacts\", evaluated on a 7-point-Likert scale (Disagree strongly = 1 ... 'Agree strongly = 7).  There are two assessments: one before and one after seeing the visual feedback, referenced in the paper and code by pre- and post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318b6a4d-7818-4fd6-a68a-683a301d3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(1, os.path.abspath('../'))\n",
    "sys.path.insert(1, os.path.abspath('../../..'))\n",
    "\n",
    "raw_data_path = \"../../data/raw\"\n",
    "processed_data_path = \"../../data/processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36c317-eb34-4ae1-b727-9aa4197b5c81",
   "metadata": {},
   "source": [
    "### Load messaging data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fb1c34-ca3d-440b-9933-28d063515760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the donation info from the data dable\n",
    "donation_table = pd.read_csv(Path(f'{raw_data_path}/donation_table_CHB_filtered.csv'))\n",
    "\n",
    "# Load donated messages from the relevant donations (e.g. those who filled in both surveys)\n",
    "messages_table = pd.read_csv(Path(f'{raw_data_path}/messages_table_CHB_filtered.csv'))\n",
    "messages_table['datetime'] = pd.to_datetime(messages_table['datetime']) # ensure the date is in datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de08be-0860-45a9-b592-becc82836477",
   "metadata": {},
   "source": [
    "### Load the metrics for calculating the chat equality index, in the paper Rgini is the default, referred to as Chat Equality Index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380f965b-0480-4bcd-a68e-cc914833a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.metrics import calculate_rGini, shannon_entropy_equality, hhi_equality,plateau_score\n",
    "metrics = {'gini': calculate_rGini,\n",
    "    'entropy': shannon_entropy_equality,\n",
    "    'hhi': hhi_equality,\n",
    "    'plateau_score':plateau_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8a9e1-db3c-4328-9978-8766eac48e9e",
   "metadata": {},
   "source": [
    "### Calculate the equality index for the entire donation period and for the last month to check for recency effects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a147632-1357-4e71-babf-2f5e5c805030",
   "metadata": {},
   "outputs": [],
   "source": [
    "donationIDs = list(donation_table['donation_id'])\n",
    "donor_info = {}\n",
    "\n",
    "for donationID in donationIDs:\n",
    "    external_id = donation_table[donation_table['donation_id']==donationID]['external_id'].iloc[0]\n",
    "    donor_info[external_id] = {}\n",
    "    \n",
    "    # Get the donor_id for the donation and separate the donor messages\n",
    "    egoID = donation_table[donation_table['donation_id']==donationID]['donor_id'].iloc[0]\n",
    "    ego_messages = messages_table[messages_table['sender_id'] == egoID]\n",
    "    # Words sent by donor in each of the chats\n",
    "    ego_wc_per_chat = ego_messages.groupby('conversation_id')['word_count'].sum()      \n",
    "    \n",
    "    # Words sent by donor per chat per month\n",
    "    ego_messages['year_month'] = pd.to_datetime(ego_messages['datetime']).dt.to_period('M')\n",
    "    monthly_word_count = ego_messages.groupby(['year_month','conversation_id'])['word_count'].sum().reset_index()\n",
    "    \n",
    "    # Organize the table by conversation ID so that the converdationIDs are row titles and the months are the columns\n",
    "    monthly_reordered = monthly_word_count.pivot(index='conversation_id', columns='year_month', values='word_count')\n",
    "    monthly_reordered = monthly_reordered.fillna(0)\n",
    "\n",
    "    # Separate the messages sent in the last month\n",
    "    last_month_values = monthly_reordered.iloc[:, -1]\n",
    "\n",
    "    # For each metric, use the corresponding function and store the values!\n",
    "    for metric_name, metric_func in metrics.items(): \n",
    "        donor_info[external_id][f'Overall {metric_name}'] = metric_func(list(ego_wc_per_chat))\n",
    "        donor_info[external_id][f'Median {metric_name}'] = np.median(monthly_reordered.apply(lambda row: metric_func(row.values.tolist()), axis=0))\n",
    "        donor_info[external_id][f'Last month {metric_name}'] = metric_func(list(last_month_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13e6f7-d88c-420a-8b76-80ca6772a1b6",
   "metadata": {},
   "source": [
    "### Combine the chat equality indices with the donor self-reports and save it all in a table for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29acedc-e80b-48c9-bc46-648c54d1696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import map_7point_likert\n",
    "objective_table = pd.DataFrame.from_dict(donor_info, orient='index').reset_index().rename(columns={'index': 'external_id'})\n",
    "question_column = 'same_wc_to_all'\n",
    "analysis = 'equality'\n",
    "\n",
    "# Load and transform the question columns relevant for this aspect\n",
    "pre_survey = map_7point_likert(Path(f'{raw_data_path}/pre-survey_CHB.xlsx'), question_column) # makes sure Likert scale is in numerical form\n",
    "post_survey = map_7point_likert(Path(f'{raw_data_path}/post-survey_CHB.xlsx'), question_column) # makes sure Likert scale is in numerical form\n",
    "combined_survey = pd.merge(pre_survey, post_survey, on='external_id', how='inner', suffixes=('_pre', '_post'))\n",
    "\n",
    "# Pair objective data with the subjective assessments based on external_id\n",
    "all_data = pd.merge(combined_survey,objective_table,on='external_id', how ='inner')\n",
    "all_data[f'{question_column}_diff'] = all_data[f'{question_column}_post'] - all_data[f'{question_column}_pre']\n",
    "all_data.to_excel(Path(f'{processed_data_path}/chat_equality_data.xlsx',index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
