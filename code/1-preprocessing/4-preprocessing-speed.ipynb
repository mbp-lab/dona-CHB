{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087ad61b-3f09-463c-bf86-1194498dcc22",
   "metadata": {},
   "source": [
    "### This notebook is used to derive metrics for quantifying the participants' speed.\n",
    "\n",
    "Absolute speed refers to how fast the participants reply to their messages, while relative speed is used to compare their speed to their contacts' speed. For absolute speed assessments, the participants replied to the question \"I reply to most of my messages within: < 1 min, 2-3 min, 3-5 min, 6-15 min, 16-30 min, 31-60 min, > 60 min.\". They could select multiple bins. For relative speed question, the participants replied to \"On average, I reply faster to my contacts than my contacts reply to me\" on a 7-point-Likert scale (Disagree strongly = 1 ... 'Agree strongly = 7).There are two assessments: one before and one after seeing the visual feedback, referenced in the code by pre- and post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9993dc5c-14a6-4953-b5b6-46ed080c108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(1, os.path.abspath('../'))\n",
    "sys.path.insert(1, os.path.abspath('../../..'))\n",
    "\n",
    "raw_data_path = \"../../data/raw\"\n",
    "processed_data_path = \"../../data/processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badc023-7807-43cd-b54c-d80b70ea2001",
   "metadata": {},
   "source": [
    "### Load messaging data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f59cdc0-3618-4cb2-8961-db0ff5c91a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the donation info from the data dable\n",
    "donation_table = pd.read_csv(Path(f'{raw_data_path}/donation_table_CHB_filtered.csv'))\n",
    "\n",
    "# Load donated messages from the relevant donations (e.g. those who filled in both surveys)\n",
    "messages_table = pd.read_csv(Path(f'{raw_data_path}/messages_table_CHB_filtered.csv'))\n",
    "messages_table['datetime'] = pd.to_datetime(messages_table['datetime']) # ensure the date is in datetime format\n",
    "messages_table['datetime'] = messages_table['datetime'].dt.round('min')  # round down to the nearest minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca9a75-2b04-4ca5-a079-4a0bc5a8e980",
   "metadata": {},
   "source": [
    "### Calculate the response probabilities of the participants (egos) and their contacts (alters) within the specified bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384ff77d-9926-4108-8356-b4b06e9b5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import bin_probability\n",
    "from modules.metrics import response_times\n",
    "\n",
    "bins = [[0, 60], [60, 3*60], [3*60, 6*60], [6*60, 16*60], [16*60, 31*60], [31*60, 60*60], [60*60, np.inf]]\n",
    "bin_labels = ['speed-<1min', 'speed-1-2min', 'speed-3-5min', 'speed-6-15min', 'speed-16-30min', 'speed-31-60min', 'speed->60min']\n",
    "\n",
    "info_dict = {}\n",
    "\n",
    "for donation_id, donor_id, external_id in zip(donation_table['donation_id'], donation_table['donor_id'], donation_table['external_id']):\n",
    "    donation_messages = messages_table[messages_table['donation_id'] == donation_id]\n",
    "    \n",
    "    # Collect all ego and alter response times across chats\n",
    "    ego_speeds = []\n",
    "    alter_speeds = []\n",
    "    \n",
    "    for _, chat in donation_messages.groupby('conversation_id'):\n",
    "        ego_chat_speeds, alter_chat_speeds = response_times(chat, donor_id)\n",
    "        ego_speeds.extend(ego_chat_speeds)\n",
    "        alter_speeds.extend(alter_chat_speeds)\n",
    "    \n",
    "    # Compute bin probabilities\n",
    "    ego_probs = bin_probability(ego_speeds, bins, bin_labels)\n",
    "    alter_probs = bin_probability(alter_speeds, bins, bin_labels)\n",
    "    \n",
    "    # Cumulative sums \n",
    "    ego_cumsum = np.cumsum(list(ego_probs.values()))\n",
    "    alter_cumsum = np.cumsum(list(alter_probs.values()))\n",
    "    \n",
    "    # Calculate the probability difference between ego and alters for responding within N minutes \n",
    "    # Deltas are calculated based on cumulative sum to be able to report \"difference in response probability within N minutes\"\n",
    "\n",
    "    delta_dict = {f'{label}-delta': ego_val - alter_val for label, ego_val, alter_val in zip(bin_labels, ego_cumsum, alter_cumsum)}\n",
    "    \n",
    "    # Next, the probabilities are stored along with absolute response times. \n",
    "    # The latter follow power law distribution and are messy to work with though. \n",
    "\n",
    "    info = {**ego_probs, **delta_dict,\n",
    "            'alter-ego-median-speed-delta': np.median(alter_speeds) - np.median(ego_speeds),\n",
    "            'ego-median-speed': np.median(ego_speeds)}\n",
    "    \n",
    "    info_dict[external_id] = info\n",
    "\n",
    "# Create final table\n",
    "speed_table = pd.DataFrame.from_dict(info_dict, orient='index').reset_index().rename(columns={'index': 'external_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0b96c-9ad8-4b72-a5bc-e391c8b1a6b2",
   "metadata": {},
   "source": [
    "### Absolute speed saving\n",
    "\n",
    "Combine the speed metrics with the donor self-reports and save it all in a table for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4d2506-902b-425c-bcc9-a5c15d19a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_survey = pd.read_excel(Path(f'{raw_data_path}/pre-survey_CHB.xlsx'))[['external_id']+bin_labels]\n",
    "post_survey = pd.read_excel(Path(f'{raw_data_path}/post-survey_CHB.xlsx'))[['external_id']+bin_labels]\n",
    "\n",
    "# Map the strings to numerical values\n",
    "bin_response_mapping = {'Yes': 1, 'No': 0}\n",
    "for col in bin_labels:\n",
    "    pre_survey[f'{col}'] = pre_survey[f'{col}'].map(bin_response_mapping)\n",
    "    post_survey[f'{col}'] = post_survey[f'{col}'].map(bin_response_mapping)\n",
    "    \n",
    "absolute_survey = pd.merge(pre_survey, post_survey, on='external_id', how='inner', suffixes=('_pre', '_post'))\n",
    "absolute_survey = absolute_survey.dropna(subset=[f\"{col}_pre\" for col in bin_labels] + [f\"{col}_post\" for col in bin_labels])\n",
    "absolute_speed_data = pd.merge(absolute_survey,speed_table[['external_id']+bin_labels],on='external_id', how ='inner')\n",
    "absolute_speed_data.to_excel(Path(f'{processed_data_path}/absolute_speed_data.xlsx'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86105c-c72f-4c56-b105-66835581483d",
   "metadata": {},
   "source": [
    "### Relative speed saving \n",
    "Combine the speed metrics with the donor self-reports and save it all in a table for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54da44d0-9df9-4b36-833d-4d59f915a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import map_7point_likert\n",
    "question_column = 'faster_response'\n",
    "\n",
    "# Load and transform the question columns relevant for this aspect\n",
    "pre_survey = map_7point_likert(Path(f'{raw_data_path}/pre-survey_CHB.xlsx'), question_column) # makes sure Likert scale is in numerical form\n",
    "post_survey = map_7point_likert(Path(f'{raw_data_path}/post-survey_CHB.xlsx'), question_column) # makes sure Likert scale is in numerical form\n",
    "relative_survey = pd.merge(pre_survey, post_survey, on='external_id', how='inner', suffixes=('_pre', '_post'))\n",
    "relative_survey[f'{question_column}_diff'] = relative_survey[f'{question_column}_post'] - relative_survey[f'{question_column}_pre']\n",
    "\n",
    "# Pair objective data with the subjective assessments based on exterenal_id\n",
    "all_data = pd.merge(relative_survey,speed_table,on='external_id', how ='inner')\n",
    "all_data.to_excel(Path(f'{processed_data_path}/relative_speed_data.xlsx'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
